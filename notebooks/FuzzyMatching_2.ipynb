{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fast Fuzzy Matching 2.0\r\n",
        "Using cosine similarity, we are able to increase the speed of fuzzy matching by up to 40X for large scale data sets of 100 Million or more comparisons."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Python Libraries"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install rapidfuzz #!conda install -c conda-forge rapidfuzz --yes\r\n",
        "#!pip install cython\r\n",
        "#!pip install sparse_dot_topn"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688063273942
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\r\n",
        "import re\r\n",
        "import time\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import operator\r\n",
        "import rapidfuzz\r\n",
        "from rapidfuzz import process, fuzz, utils\r\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n",
        "from scipy.sparse import csr_matrix\r\n",
        "import sparse_dot_topn.sparse_dot_topn as ct"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688063274594
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nasdaq = pd.read_csv('data/nasdaq.csv')\r\n",
        "sp500 = pd.read_csv('data/s_and_p_500.csv')\r\n",
        "nyse = pd.read_csv('data/nyse.csv')\r\n",
        "other = pd.read_csv('data/other.csv')\r\n",
        "sec = pd.read_csv('data/sec_edgar_company_info.csv')\r\n",
        "\r\n",
        "nasdaq['Stock Exchange'] = 'Nasdaq'\r\n",
        "sp500['Stock Exchange'] = 'S&P 500'\r\n",
        "nyse['Stock Exchange'] = 'NYSE'\r\n",
        "other['Stock Exchange'] = 'Other'\r\n",
        "\r\n",
        "stocks = pd.concat([nasdaq,sp500,nyse,other])\r\n",
        "stocks = stocks.drop_duplicates(subset = 'Symbol')"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688063275488
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stocks.head(2)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "  Symbol                                       Company Name Stock Exchange\n0   AAIT  iShares MSCI All Country Asia Information Tech...         Nasdaq\n1    AAL                      American Airlines Group, Inc.         Nasdaq",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Symbol</th>\n      <th>Company Name</th>\n      <th>Stock Exchange</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAIT</td>\n      <td>iShares MSCI All Country Asia Information Tech...</td>\n      <td>Nasdaq</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAL</td>\n      <td>American Airlines Group, Inc.</td>\n      <td>Nasdaq</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688063275671
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sec.head(2)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "                    Company Name  Company CIK Key\n0                         !J INC          1438823\n1  #1 A LIFESAFER HOLDINGS, INC.          1509607",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Company Name</th>\n      <th>Company CIK Key</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>!J INC</td>\n      <td>1438823</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>#1 A LIFESAFER HOLDINGS, INC.</td>\n      <td>1509607</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688063275839
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-processing\r\n",
        "Pre-processing strings in both datasets by replacing non-alphanumeric characters with whitespace, making strings lowercase, and stripping added whitespace."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\r\n",
        "stocks['Company Name Clean'] = stocks['Company Name'].apply(lambda x: utils.default_process(x)).str.replace('[^A-z0-9 ]+', '').str.replace(' +', ' ')\r\n",
        "sec['Company Name Clean'] = sec['Company Name'].astype(str).apply(lambda x: utils.default_process(x)).str.replace('[^A-z0-9 ]+', '').str.replace(' +', ' ')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 2.23 s, sys: 58.9 ms, total: 2.29 s\nWall time: 2.29 s\n"
        }
      ],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full Match\r\n",
        "Once the pre-processing is complete, we want to first perform a full match on the cleaned company names to reduce the complexity of the fuzzy matching on remaining names."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stocks_full_match = stocks.merge(sec, how = 'inner', on = 'Company Name Clean', suffixes = (' Set A', ' Set B'))\\\r\n",
        "\r\n",
        "print(len(stocks_full_match), 'full matches out of', len(stocks),\r\n",
        "      '({:.1%})'.format(len(stocks_full_match)/len(stocks)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "2628 full matches out of 8190 (32.1%)\n"
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688063278223
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate unmatched stocks and SEC companies to use for fuzzy matching\r\n",
        "stocks_not_matched = stocks[~stocks['Company Name Clean'].isin(stocks_full_match['Company Name Clean'])]\r\n",
        "sec_not_matched = sec[~sec['Company Name Clean'].isin(stocks_full_match['Company Name Clean'])]\r\n",
        "\r\n",
        "print(len(stocks_not_matched), 'stocks not matched out of', len(stocks),\r\n",
        "      '({:.1%})'.format(len(stocks_not_matched)/len(stocks)))\r\n",
        "print(len(sec_not_matched), 'SEC companies not matched out of', len(stocks),\r\n",
        "      '({:.1%})'.format(len(sec_not_matched)/len(sec)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "5904 stocks not matched out of 8190 (72.1%)\n660559 SEC companies not matched out of 8190 (99.6%)\n"
        }
      ],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688063278391
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fast Fuzzy Match\r\n",
        "Extract the best match for each stock against the 660k SEC company names and use a score cutoff of 90% match to join the 2 datasets on approximate company name"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load libraries\r\n",
        "#import re\r\n",
        "#import time\r\n",
        "#import operator\r\n",
        "#import numpy as np\r\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\r\n",
        "#from scipy.sparse import csr_matrix\r\n",
        "#import pandas as pd\r\n",
        "\r\n",
        "#import sparse_dot_topn.sparse_dot_topn as ct\r\n",
        "\r\n",
        "# A class for matching one list of strings to another\r\n",
        "class StringMatch():\r\n",
        "    \r\n",
        "    def __init__(self, source_names, target_names):\r\n",
        "        self.source_names = source_names\r\n",
        "        self.target_names = target_names\r\n",
        "        self.ct_vect      = None\r\n",
        "        self.tfidf_vect   = None\r\n",
        "        self.vocab        = None\r\n",
        "        self.sprse_mtx    = None\r\n",
        "        \r\n",
        "        \r\n",
        "    def tokenize(self, analyzer='char_wb', n=3):\r\n",
        "        '''\r\n",
        "        Tokenizes the list of strings, based on the selected analyzer\r\n",
        "        :param str analyzer: Type of analyzer ('char_wb', 'word'). Default is trigram\r\n",
        "        :param str n: If using n-gram analyzer, the gram length\r\n",
        "        '''\r\n",
        "        # Create initial count vectorizer & fit it on both lists to get vocab\r\n",
        "        self.ct_vect = CountVectorizer(analyzer=analyzer, ngram_range=(n, n))\r\n",
        "        self.vocab   = self.ct_vect.fit(self.source_names + self.target_names).vocabulary_\r\n",
        "        \r\n",
        "        # Create tf-idf vectorizer\r\n",
        "        self.tfidf_vect  = TfidfVectorizer(vocabulary=self.vocab, analyzer=analyzer, ngram_range=(n, n))\r\n",
        "        \r\n",
        "        \r\n",
        "    def match(self, ntop=1, lower_bound=0, output_fmt='df'):\r\n",
        "        '''\r\n",
        "        Main match function. Default settings return only the top candidate for every source string.\r\n",
        "        \r\n",
        "        :param int ntop: The number of top-n candidates that should be returned\r\n",
        "        :param float lower_bound: The lower-bound threshold for keeping a candidate, between 0-1.\r\n",
        "                                   Default set to 0, so consider all canidates\r\n",
        "        :param str output_fmt: The output format. Either dataframe ('df') or dict ('dict')\r\n",
        "        '''\r\n",
        "        self._awesome_cossim_top(ntop, lower_bound)\r\n",
        "        \r\n",
        "        if output_fmt == 'df':\r\n",
        "            match_output = self._make_matchdf()\r\n",
        "        elif output_fmt == 'dict':\r\n",
        "            match_output = self._make_matchdict()\r\n",
        "            \r\n",
        "        return match_output\r\n",
        "        \r\n",
        "        \r\n",
        "    def _awesome_cossim_top(self, ntop, lower_bound):\r\n",
        "        ''' https://gist.github.com/ymwdalex/5c363ddc1af447a9ff0b58ba14828fd6#file-awesome_sparse_dot_top-py '''\r\n",
        "        # To CSR Matrix, if needed\r\n",
        "        A = self.tfidf_vect.fit_transform(self.source_names).tocsr()\r\n",
        "        B = self.tfidf_vect.fit_transform(self.target_names).transpose().tocsr()\r\n",
        "        M, _ = A.shape\r\n",
        "        _, N = B.shape\r\n",
        "\r\n",
        "        idx_dtype = np.int32\r\n",
        "\r\n",
        "        nnz_max = M * ntop\r\n",
        "\r\n",
        "        indptr = np.zeros(M+1, dtype=idx_dtype)\r\n",
        "        indices = np.zeros(nnz_max, dtype=idx_dtype)\r\n",
        "        data = np.zeros(nnz_max, dtype=A.dtype)\r\n",
        "\r\n",
        "        ct.sparse_dot_topn(\r\n",
        "            M, N, np.asarray(A.indptr, dtype=idx_dtype),\r\n",
        "            np.asarray(A.indices, dtype=idx_dtype),\r\n",
        "            A.data,\r\n",
        "            np.asarray(B.indptr, dtype=idx_dtype),\r\n",
        "            np.asarray(B.indices, dtype=idx_dtype),\r\n",
        "            B.data,\r\n",
        "            ntop,\r\n",
        "            lower_bound,\r\n",
        "            indptr, indices, data)\r\n",
        "\r\n",
        "        self.sprse_mtx = csr_matrix((data,indices,indptr), shape=(M,N))\r\n",
        "    \r\n",
        "    \r\n",
        "    def _make_matchdf(self):\r\n",
        "        ''' Build dataframe for result return '''\r\n",
        "        # CSR matrix -> COO matrix\r\n",
        "        cx = self.sprse_mtx.tocoo()\r\n",
        "\r\n",
        "        # COO matrix to list of tuples\r\n",
        "        match_list = []\r\n",
        "        for row,col,val in zip(cx.row, cx.col, cx.data):\r\n",
        "            match_list.append((row, self.source_names[row], col, self.target_names[col], val))\r\n",
        "\r\n",
        "        # List of tuples to dataframe\r\n",
        "        colnames = ['Set_A_Index', 'Set_A', 'Set_B_Index', 'Set_B', 'Match Ratio']\r\n",
        "        match_df = pd.DataFrame(match_list, columns=colnames)\r\n",
        "        match_df['Match Ratio'] = match_df['Match Ratio'] * 100\r\n",
        "\r\n",
        "        return match_df\r\n",
        "\r\n",
        "    \r\n",
        "    def _make_matchdict(self):\r\n",
        "        ''' Build dictionary for result return '''\r\n",
        "        # CSR matrix -> COO matrix\r\n",
        "        cx = self.sprse_mtx.tocoo()\r\n",
        "\r\n",
        "        # dict value should be tuple of values\r\n",
        "        match_dict = {}\r\n",
        "        for row,col,val in zip(cx.row, cx.col, cx.data):\r\n",
        "            if match_dict.get(row):\r\n",
        "                match_dict[row].append((col,val))\r\n",
        "            else:\r\n",
        "                match_dict[row] = [(col, val)]\r\n",
        "\r\n",
        "        return match_dict   \r\n",
        "\r\n",
        "def fast_fuzzy_match(df1,col1,df2,col2,num_matches=1,cutoff=0):\r\n",
        "    titlematch = StringMatch(df1[col1].tolist(), df2[col2].tolist())\r\n",
        "    titlematch.tokenize()\r\n",
        "    nlp_df = titlematch.match(ntop=num_matches,lower_bound=(cutoff/100))\r\n",
        "    return nlp_df"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688063278544
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\r\n",
        "# Run the fuzzy match logic on the SEC and company data\r\n",
        "score_cutoff = 80\r\n",
        "set_a = stocks_not_matched\r\n",
        "col_a = 'Company Name Clean'\r\n",
        "set_b = sec_not_matched\r\n",
        "col_b = 'Company Name Clean'\r\n",
        "\r\n",
        "df = fast_fuzzy_match(set_a,col_a, set_b, col_b,cutoff=score_cutoff)\r\n",
        "\r\n",
        "# Merge results\r\n",
        "df = stocks_not_matched.merge(df, how = 'left', left_on= 'Company Name Clean', right_on='Set_A').drop_duplicates(subset='Symbol').merge(sec_not_matched, how = 'left', left_on = 'Set_B', right_on = 'Company Name Clean', suffixes = (' Set A', ' Set B')).drop_duplicates(subset='Symbol')"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "CPU times: user 56.2 s, sys: 488 ms, total: 56.7 s\nWall time: 56.6 s\n"
        }
      ],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1687971783025
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": "  Symbol                                 Company Name Set A Stock Exchange  \\\n0   AAIT  iShares MSCI All Country Asia Information Tech...         Nasdaq   \n1   AAME                      Atlantic American Corporation         Nasdaq   \n2   AAWW                       Atlas Air Worldwide Holdings         Nasdaq   \n3   AAXJ  iShares MSCI All Country Asia ex Japan Index Fund         Nasdaq   \n4   ABCO                         The Advisory Board Company         Nasdaq   \n\n                            Company Name Clean Set A  Set_A_Index  \\\n0  ishares msci all country asia information tech...          NaN   \n1                      atlantic american corporation          1.0   \n2                       atlas air worldwide holdings          2.0   \n3  ishares msci all country asia ex japan index fund          NaN   \n4                         the advisory board company          4.0   \n\n                           Set_A  Set_B_Index  \\\n0                            NaN          NaN   \n1  atlantic american corporation      44149.0   \n2   atlas air worldwide holdings      44483.0   \n3                            NaN          NaN   \n4     the advisory board company      14935.0   \n\n                              Set_B  Match Ratio  \\\n0                               NaN          NaN   \n1            atlantic american corp    91.545702   \n2  atlas air worldwide holdings inc    98.599175   \n3                               NaN          NaN   \n4                 advisory board co    85.368878   \n\n                 Company Name Set B  Company CIK Key  \\\n0                               NaN              NaN   \n1            ATLANTIC AMERICAN CORP           8177.0   \n2  ATLAS AIR WORLDWIDE HOLDINGS INC        1135185.0   \n3                               NaN              NaN   \n4                 ADVISORY BOARD CO        1157377.0   \n\n           Company Name Clean Set B  \n0                               NaN  \n1            atlantic american corp  \n2  atlas air worldwide holdings inc  \n3                               NaN  \n4                 advisory board co  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Symbol</th>\n      <th>Company Name Set A</th>\n      <th>Stock Exchange</th>\n      <th>Company Name Clean Set A</th>\n      <th>Set_A_Index</th>\n      <th>Set_A</th>\n      <th>Set_B_Index</th>\n      <th>Set_B</th>\n      <th>Match Ratio</th>\n      <th>Company Name Set B</th>\n      <th>Company CIK Key</th>\n      <th>Company Name Clean Set B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>AAIT</td>\n      <td>iShares MSCI All Country Asia Information Tech...</td>\n      <td>Nasdaq</td>\n      <td>ishares msci all country asia information tech...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>AAME</td>\n      <td>Atlantic American Corporation</td>\n      <td>Nasdaq</td>\n      <td>atlantic american corporation</td>\n      <td>1.0</td>\n      <td>atlantic american corporation</td>\n      <td>44149.0</td>\n      <td>atlantic american corp</td>\n      <td>91.545702</td>\n      <td>ATLANTIC AMERICAN CORP</td>\n      <td>8177.0</td>\n      <td>atlantic american corp</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>AAWW</td>\n      <td>Atlas Air Worldwide Holdings</td>\n      <td>Nasdaq</td>\n      <td>atlas air worldwide holdings</td>\n      <td>2.0</td>\n      <td>atlas air worldwide holdings</td>\n      <td>44483.0</td>\n      <td>atlas air worldwide holdings inc</td>\n      <td>98.599175</td>\n      <td>ATLAS AIR WORLDWIDE HOLDINGS INC</td>\n      <td>1135185.0</td>\n      <td>atlas air worldwide holdings inc</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>AAXJ</td>\n      <td>iShares MSCI All Country Asia ex Japan Index Fund</td>\n      <td>Nasdaq</td>\n      <td>ishares msci all country asia ex japan index fund</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ABCO</td>\n      <td>The Advisory Board Company</td>\n      <td>Nasdaq</td>\n      <td>the advisory board company</td>\n      <td>4.0</td>\n      <td>the advisory board company</td>\n      <td>14935.0</td>\n      <td>advisory board co</td>\n      <td>85.368878</td>\n      <td>ADVISORY BOARD CO</td>\n      <td>1157377.0</td>\n      <td>advisory board co</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688063335275
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(df.dropna(subset = ['Company CIK Key'])), 'stocks matched out of', len(stocks),\r\n",
        "      '({:.1%})'.format(len(df.dropna(subset = ['Company CIK Key']))/len(stocks)))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "3094 stocks matched out of 8190 (37.8%)\n"
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1688063351384
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}